{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSDS 7331 Mini - Project 1  \n",
    "\n",
    "## SVM and Logistic Modeling\n",
    "\n",
    "Professor: Dr. Jake Drew  \n",
    "Team: Steven Hayden, Josephine MacDaniel, Korey MacVittie, Afreen Siddiqui, Eduardo Cantu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mp1\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data\n",
    "Accident_df_2016 = pd.read_csv('https://raw.githubusercontent.com/ecantu75/DataMining_Lab1/master/Data/accident_2016.csv',low_memory=False)\n",
    "Accident_df_2015 = pd.read_csv('https://raw.githubusercontent.com/ecantu75/DataMining_Lab1/master/Data/accident_2015.csv',low_memory=False)\n",
    "Accident_df = pd.concat([Accident_df_2015,Accident_df_2016])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displays the record count of non-null Values per attribute and their data type. \n",
    "Accident_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#check for duplicate records. It displays the maximum count of a duplicated record. \n",
    "#Any value greater than 1 would mean that the data has duplicates\n",
    "Accident_df['consecutive_number'].value_counts().max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop duplicate records and keeps the most recent record. We assume the most resent is the most accurate \n",
    "Accident_df = Accident_df.drop_duplicates(['consecutive_number'],keep = 'last')\n",
    "\n",
    "#check for duplicate records. It displays the maximum count of a duplicated record. \n",
    "#Any value greater than 1 would mean that the data has duplicates\n",
    "Accident_df['consecutive_number'].value_counts().max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many accidents with missing data regarding the crash time and the arrival time of responders. This information is need for the dependent variable and in turn is crucial for our analysis. That is why it was decided to drop these records with missing data instead of filling the gaps with the mean.  The amount records dropped is about a third of the original data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove any recoreds without  time informaiton for arival and crash time\n",
    "count_no_rec= Accident_df[(Accident_df['hour_of_crash']>24) | (Accident_df['hour_of_arrival_at_scene']>24)]\n",
    "Accident_df = Accident_df[(Accident_df['hour_of_crash']<=24) & (Accident_df['hour_of_arrival_at_scene']<=24)]\n",
    "print(count_no_rec.consecutive_number.count(), 'records were removed due to missing time data.') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new Feature. This is the ratio between the number of fatalities and the people involved in the accident.\n",
    "Accident_df['Fatalities_ratio'] = Accident_df.number_of_fatalities/(Accident_df.number_of_persons_not_in_motor_vehicles_in_transport_mvit + Accident_df.number_of_persons_in_motor_vehicles_in_transport_mvit)\n",
    "\n",
    "#Converts hour and min to datetime type\n",
    "#crash\n",
    "Accident_df.hour_of_crash = pd.to_timedelta(Accident_df.hour_of_crash,unit ='h')\n",
    "Accident_df.minute_of_crash= pd.to_timedelta(Accident_df.minute_of_crash,unit ='m')\n",
    "#arrival\n",
    "Accident_df.hour_of_arrival_at_scene = pd.to_timedelta(Accident_df.hour_of_arrival_at_scene,unit ='h')\n",
    "Accident_df.minute_of_arrival_at_scene = pd.to_timedelta(Accident_df.minute_of_arrival_at_scene,unit ='m')\n",
    "\n",
    "#concatenates Hour and Minutes together \n",
    "Accident_df['Crash_Time'] = Accident_df['hour_of_crash'] + Accident_df['minute_of_crash'] \n",
    "Accident_df['Arrival_Time'] = Accident_df['hour_of_arrival_at_scene'] + Accident_df['minute_of_arrival_at_scene']\n",
    "#creates a response_time variable from the two fields above and converts to min\n",
    "Accident_df['Response_Time'] = Accident_df['Arrival_Time'] - Accident_df['Crash_Time']\n",
    "total_response_time_in_min = pd.DatetimeIndex(Accident_df['Response_Time'])\n",
    "Accident_df['Response_Time']= total_response_time_in_min.hour * 60 + total_response_time_in_min.minute\n",
    "\n",
    "\n",
    "#gut check of calculation \n",
    "Accident_df[['hour_of_crash','minute_of_crash','Crash_Time','hour_of_arrival_at_scene','minute_of_arrival_at_scene','Arrival_Time','Response_Time']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The National Fire Protection Association's (NFPA) has established standard for response time and procedures for Emergency Medical Service (EMS) to adhere to. \n",
    "\n",
    "From EMSword.com \"The NFPA 1710 standard is based upon a combination of accepted practices and more than 30 years of study, research, testing and validation. Members of the 1710 committee that developed the standard include representatives from various fire agencies and the International Association of City/County Managers (ICMA).\"\n",
    "\n",
    "The NFPA 1710 standard allows for a one-minute call evaluation and preparation, four minutes for the arrival of a unit with first responder. For a situation that requires an advanced life support equipment like an ambulance, their standard is 8 minutes after the call preparation.  \n",
    "\n",
    "We chose to use their standards as threshold to determine if the paramedics got to the scene of the accident in time. This would be a binary response 0, for not arriving within 9 minutes of the accident and 1 for being within the 9 minutes. \n",
    "Source: https://www.emsworld.com/article/10324786/ems-response-time-standards\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates the binary variable 'within 9 minutes NFPA standard'\n",
    "Accident_df['within 9 minutes NFPA standard'] = np.where(Accident_df['Response_Time']<=9,1,0)\n",
    "#Accident_df[['Response_Time','within 9 minutes NFPA standard']].head(10) # Verify the binary variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the logistic regresion will predict if the paramedic got on time to the scene of the accident we would select the attributes that we think affect this variable.\n",
    "\n",
    "First we would check what columns are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displays all the available attributes on the dataset\n",
    "Accident_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From all the attributes in the dataset we would only select a subset to predict the if the paramedics will arrive on time or not.  \n",
    "* **state_name:** This attribute can give us an indication if there are states that would have a better response time in an accident than others.\n",
    "* **route_signing_name:** This can give us an insigth on the type of roads where the paramedics find more challenging to get.  \n",
    "* **light_condition_name:** We want to underdstand how much the lightning coditions affect the ability of the paramedics to get on time to the scene of the accident.  \n",
    "* **atmospheric_conditions_name:** Adding this attribute, we want to see how the weather conditions affect the reaction time of the paramedics.  \n",
    "* **within 9 minutes NFPA standard:**  This is our response variable, where 1 means that the paramedics get on time to the scene of the accident. As mentioned before, this threshold is set by the NFPA and is 9 minutes. This field will be 0 if the paramedics take more than 9 minutes to get the the accident."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a copy of the original Data\n",
    "Accident_forLr=Accident_df.copy()\n",
    "\n",
    "# 1. Remove attributes that just arent useful for us\n",
    "for col in ['Unnamed: 0',\n",
    "             'state_number',\n",
    "             'consecutive_number',\n",
    "             'county',\n",
    "             'city',\n",
    "             'day_of_crash',\n",
    "             'month_of_crash',\n",
    "             'year_of_crash',\n",
    "             'day_of_week',\n",
    "             'hour_of_crash',\n",
    "             'minute_of_crash',\n",
    "             'national_highway_system',\n",
    "             'land_use',\n",
    "             'land_use_name',\n",
    "             'functional_system',\n",
    "             'functional_system_name',\n",
    "             'ownership',\n",
    "             'ownership_name',\n",
    "             'route_signing',\n",
    "             'trafficway_identifier',\n",
    "             'trafficway_identifier_2',\n",
    "             'latitude',\n",
    "             'longitude',\n",
    "             'special_jurisdiction',\n",
    "             'special_jurisdiction_name',\n",
    "             'first_harmful_event',\n",
    "             'first_harmful_event_name',\n",
    "             'manner_of_collision',\n",
    "             'manner_of_collision_name',\n",
    "             'relation_to_junction_within_interchange_area',\n",
    "             'relation_to_junction_specific_location',\n",
    "             'relation_to_junction_specific_location_name',\n",
    "             'type_of_intersection',\n",
    "             'work_zone',\n",
    "             'relation_to_trafficway',\n",
    "             'relation_to_trafficway_name',\n",
    "             'light_condition',\n",
    "             'atmospheric_conditions_1',\n",
    "             'atmospheric_conditions_1_name',\n",
    "             'atmospheric_conditions_2',\n",
    "             'atmospheric_conditions_2_name',\n",
    "             'atmospheric_conditions',\n",
    "             'school_bus_related',\n",
    "             'rail_grade_crossing_identifier',\n",
    "             'hour_of_notification',\n",
    "             'minute_of_notification',\n",
    "             'hour_of_arrival_at_scene',\n",
    "             'minute_of_arrival_at_scene',\n",
    "             'hour_of_ems_arrival_at_hospital',\n",
    "             'minute_of_ems_arrival_at_hospital',\n",
    "             'related_factors_crash_level_1',\n",
    "             'related_factors_crash_level_1_name',\n",
    "             'related_factors_crash_level_2',\n",
    "             'related_factors_crash_level_2_name',\n",
    "             'related_factors_crash_level_3',\n",
    "             'related_factors_crash_level_3_name',\n",
    "             'milepoint',\n",
    "             'number_of_parked_working_vehicles',\n",
    "             'number_of_forms_submitted_for_persons_not_in_motor_vehicles',\n",
    "             'number_of_persons_not_in_motor_vehicles_in_transport_mvit',\n",
    "             'number_of_persons_in_motor_vehicles_in_transport_mvit',\n",
    "             'number_of_forms_submitted_for_persons_in_motor_vehicles',\n",
    "             'timestamp_of_crash',\n",
    "             'number_of_fatalities',\n",
    "             'number_of_drunk_drivers',\n",
    "             'Fatalities_ratio',\n",
    "             'number_of_vehicle_forms_submitted_all',\n",
    "             'Crash_Time',\n",
    "             'Arrival_Time',\n",
    "             'Response_Time',\n",
    "             'number_of_motor_vehicles_in_transport_mvit']:\n",
    "                    if col in Accident_forLr:\n",
    "                        del Accident_forLr[col]\n",
    "# List the columns left in the df\n",
    "list(Accident_forLr)\n",
    "\n",
    "#Accident_forLr.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any observation value on the selected attributes that is reported as *Unknown, Other, or Not Reported* would be removed from the dataset. This values do not bring any value when it comes to predict the response time of the paramedics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for columns that might not be needed\n",
    "print(\"Unique values for 'route_signing_name':\" , Accident_forLr.atmospheric_conditions_name.unique(), \"\\n\")\n",
    "print(\"Unique values for 'atmospheric_conditions_name':\" , Accident_forLr.atmospheric_conditions_name.unique(), \"\\n\")\n",
    "print(\"Unique values for 'light_condition_name':\" , Accident_forLr.light_condition_name.unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes observations with an unknown informaiton in the route, atmospheric conditions and state name\n",
    "Accident_forLr= Accident_forLr[(Accident_forLr['route_signing_name'] != 'Unknown')]\n",
    "Accident_forLr= Accident_forLr[(Accident_forLr['route_signing_name'] != 'Other')]\n",
    "Accident_forLr= Accident_forLr[(Accident_forLr['atmospheric_conditions_name'] != 'Unknown')]\n",
    "Accident_forLr= Accident_forLr[(Accident_forLr['atmospheric_conditions_name'] != 'Other')]\n",
    "Accident_forLr= Accident_forLr[(Accident_forLr['atmospheric_conditions_name'] != 'Not Reported')]\n",
    "Accident_forLr= Accident_forLr[(Accident_forLr['light_condition_name'] != 'Unknown')]\n",
    "Accident_forLr= Accident_forLr[(Accident_forLr['light_condition_name'] != 'Other')]\n",
    "Accident_forLr= Accident_forLr[(Accident_forLr['light_condition_name'] != 'Not Reported')]\n",
    "Accident_forLr.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review that the observations have been removed from the dataset. The undesired obsrvations are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unique values for 'route_signing_name':\" , Accident_forLr.atmospheric_conditions_name.unique(), \"\\n\")\n",
    "print(\"Unique values for 'atmospheric_conditions_name':\" , Accident_forLr.atmospheric_conditions_name.unique(), \"\\n\")\n",
    "print(\"Unique values for 'light_condition_name':\" , Accident_forLr.light_condition_name.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange colums\n",
    "Accident_forLr=Accident_forLr[['within 9 minutes NFPA standard','state_name','route_signing_name','atmospheric_conditions_name','light_condition_name']]\n",
    "#list(Accident_forLr)  # Check for the correct column sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The section below will perform the one-hot encoding of the variables on the dataset. This is to prepare the data in such a way that can be use for our logistic regresion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform one-hot encoding of the categorical data \"state_name\"\n",
    "tmp_state_df = pd.get_dummies(Accident_forLr.state_name,prefix='state')\n",
    "#tmp_state_df.head(20)\n",
    "\n",
    "# perform one-hot encoding of the categorical data \"route_signing_name\"\n",
    "tmp_route_df = pd.get_dummies(Accident_forLr.route_signing_name,prefix='route')\n",
    "#tmp_route_df.head(20)\n",
    "\n",
    "# perform one-hot encoding of the categorical data \"atmospheric_conditions_name\"\n",
    "tmp_atmos_df = pd.get_dummies(Accident_forLr.atmospheric_conditions_name,prefix='atmos')\n",
    "#tmp_atmos_df.head(20)\n",
    "\n",
    "# perform one-hot encoding of the categorical data \"atmospheric_conditions_name\"\n",
    "tmp_light_df = pd.get_dummies(Accident_forLr.light_condition_name, prefix='light')\n",
    "#tmp_atmos_df.head(20)\n",
    "\n",
    "Accident_forLr = pd.concat((Accident_forLr,tmp_state_df,tmp_route_df,tmp_atmos_df,tmp_light_df), axis=1) # add back into the dataframe\n",
    "list(Accident_forLr)\n",
    "#delete the categorical variable columns\n",
    "del Accident_forLr['state_name']\n",
    "del Accident_forLr['route_signing_name']\n",
    "del Accident_forLr['atmospheric_conditions_name']\n",
    "del Accident_forLr['light_condition_name']\n",
    "\n",
    "#list(Accident_forLr) # Check for the last colums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accident_forLr.count() # Count Records and show columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Split and Cross Validation Setup\n",
    "In this logistic regresion we would be splitting our dataset into a Training and Test set. The split is going to be 80 % for training and the other 20 % for testing. The ratio used is accepted split in the research community, and we did not see any reason to deviate from this ratio. A Cross Validation of ten fold would be performed to validate the model. \n",
    "\n",
    "* Binary Response: *'within 9 minutes NFPA standard'*\n",
    "\n",
    "|Value|Description|\n",
    "|-----|:-----------|\n",
    "|0| Time of arrival > 9 minutes|\n",
    "|1| Time of arrival <=9 minutes|\n",
    "\n",
    "* To have the same random test and traning set each time the cross validation is perform we would use a random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code addapted from the Dataming Notbooks. Logistic Regression Notbook 4.\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# we want to predict the X and y data as follows:\n",
    "if 'within 9 minutes NFPA standard' in Accident_forLr:\n",
    "    y = Accident_forLr['within 9 minutes NFPA standard'].values # get the labels we want\n",
    "    del Accident_forLr['within 9 minutes NFPA standard'] # get rid of the class label\n",
    "    X = Accident_forLr.values # use everything else to predict!\n",
    "    \n",
    "        ## X and y are now numpy matrices, by calling 'values' on the pandas data frames we\n",
    "        #    have converted them into simple matrices to use with scikit learn\n",
    "\n",
    "# to use the cross validation object in scikit learn, we need to grab an instance\n",
    "#    of the object and set it up. This object will be able to split our data into \n",
    "#    training and testing splits\n",
    "num_cv_iterations = 10  #number of Cross Validation folds\n",
    "num_instances = len(y)\n",
    "\n",
    "# Cross Validation Object\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2,\n",
    "                          random_state=55)\n",
    "                         \n",
    "print(X) # This prints all the dependant variables\n",
    "print(cv_object) # This print the Data split object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model Setup  \n",
    "This will use the cv_object to run the cross validation for the logistic regression on the *within 9 minutes NFPA standard* binary varable. At this point the data has been split into training and test. \n",
    "\n",
    "For this dataset there is an unbalance in the binary response variable. There are 1615 positive values and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code addapted from the Dataming Notbooks. Logistic Regression Notbook 4.\n",
    "# run logistic regression and vary some parameters\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "# first we create a reusable logisitic regression object\n",
    "#   here we can setup the object with different learning parameters and constants\n",
    "OnTime_lr_clf = LogisticRegression(penalty='l2', C=0.25, class_weight=None) # get object\n",
    "\n",
    "# now we can use the cv_object that we setup before to iterate through the \n",
    "#    different training and testing sets. Each time we will reuse the logisitic regression \n",
    "#    object, but it gets trained on different data each time we use it.\n",
    "\n",
    "iter_num=0\n",
    "acc_List = []\n",
    "# the indices are the rows used for training and testing in each iteration\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    # I will create new variables here so that it is more obvious what \n",
    "    # the code is doing (you can compact this syntax and avoid duplicating memory,\n",
    "    # but it makes this code less readable)\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    # train the reusable logisitc regression model on the training data\n",
    "    OnTime_lr_clf.fit(X_train,y_train)  # train object\n",
    "    y_hat = OnTime_lr_clf.predict(X_test) # get test set precitions\n",
    "\n",
    "    # now let's get the accuracy and confusion matrix for this iterations of training/testing\n",
    "    acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "    print(\"accuracy\", acc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    acc_List.append(acc)\n",
    "    iter_num+=1\n",
    "\n",
    "    \n",
    "# The Code above randomly creates a new training and testing set\n",
    "# so there will multiple accuracy measurements\n",
    "# We have taken the of all these measurements below\n",
    "\n",
    "print('\\n','\\n','\\n','\\n',\"==========================\") \n",
    "print(\"average accuracy\",np.mean(acc_List))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The mean of the 10-fold cross validation is indicated above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On this section we will perform a serch for the best model using *Grid Search*. A range of parameters is given and search algorithm will try all parameter conbinations.\n",
    "For this large dataset, the solver option in the model would use *sag* to have it perform faster than the *liblinear*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code addapted from the notebook 'ComparingSegregatedHighSchoolCampuses.ipynb' to make a grid search for the best model\n",
    "parameters = { 'penalty':['l2']\n",
    "              ,'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "              ,'class_weight': ['balanced', 'none']\n",
    "              ,'random_state': [0]\n",
    "              ,'solver': ['sag']\n",
    "              ,'max_iter':[100,500]\n",
    "             }\n",
    "\n",
    "#Create a grid search object using the  \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "regGridSearch = GridSearchCV(estimator=OnTime_lr_clf\n",
    "                   , n_jobs=8 # jobs to run in parallel\n",
    "                   , verbose=1 # low verbosity\n",
    "                   , param_grid=parameters\n",
    "                   , cv=num_cv_iterations # KFolds = 10\n",
    "                   , scoring='accuracy')\n",
    "\n",
    "# Perform the seaarch throught all the parameters in the parameters dictionary\n",
    "regGridSearch.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Diplay the top model parameters\n",
    "regGridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "#Use the best parameters for our Linear Regression object\n",
    "OntimeClassifierEst = regGridSearch.best_estimator_\n",
    "\n",
    "bestScores = cross_validate(OntimeClassifierEst,X,y,scoring=['accuracy','precision','recall'], cv=num_cv_iterations, return_train_score=True)\n",
    "\n",
    "\n",
    "# grab the results from the dictionary into a dataframe\n",
    "cvScoreResult = pd.DataFrame()\n",
    "cvScoreResult['Accuracy'] = bestScores['test_accuracy']\n",
    "cvScoreResult['Precision'] = bestScores['test_precision']\n",
    "cvScoreResult['Recall'] = bestScores['test_recall']\n",
    "\n",
    "\n",
    "print('Cross Validation Fold Mean Error Scores')\n",
    "print(cvScoreResult)\n",
    "\n",
    "avgAccuracy = bestScores['test_accuracy'].mean()\n",
    "avgPrecision = bestScores['test_precision'].mean()\n",
    "avgRecall = bestScores['test_recall'].mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to run through the cross validation loop and set the training and testing variable for one single iteration \n",
    "#Code addapted from the Dataming Notbooks. Logistic Regression and SVM Notbook 4\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    # I will create new variables here so that it is more obvious what \n",
    "    # the code is doing (you can compact this syntax and avoid duplicating memory,\n",
    "    # but it makes this code less readable)\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "#scale attributes by the training set\n",
    "scl_obj = StandardScaler()\n",
    "scl_obj.fit(X_train)\n",
    "X_train_scaled = scl_obj.transform(X_train) # apply to training\n",
    "X_test_scaled = scl_obj.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets investigate SVMs on the data and play with the parameters and kernels\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# train the model just as before\n",
    "svm_clf = SVC(C=0.5, kernel='rbf', degree=3, gamma='auto') # get object\n",
    "svm_clf.fit(X_train, y_train)  # train object\n",
    "\n",
    "y_hat = svm_clf.predict(X_test) # get test set precitions\n",
    "\n",
    "acc = mt.accuracy_score(y_test,y_hat)\n",
    "conf = mt.confusion_matrix(y_test,y_hat)\n",
    "print('accuracy:', acc )\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "X, y = make_blobs(n_samples=100, centers=2,\n",
    "                  random_state=0, cluster_std=0.60)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Linear Kernel (source: https://stackabuse.com/implementing-svm-and-kernel-svm-with-pythons-scikit-learn/)\n",
    "svclassifier = SVC(kernel='linear')  \n",
    "svclassifier.fit(X_train_scaled, y_train) \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To make predictions, the predict method of the SVC class is used. \n",
    "y_pred = svclassifier.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix, precision, recall, and F1 measures are the most commonly used metrics for classification tasks. \n",
    "#Scikit-Learn's metrics library contains the classification_report and confusion_matrix methods, which can be readily used to find out the values for these important metrics.\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## using linear kernel to get the bar chart of coef weights\n",
    "print(svclassifier.coef_)\n",
    "weights = pd.Series(svclassifier.coef_[0],index=Accident_forLr.columns)\n",
    "weights.plot(kind='bar', figsize=(15, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xfit = np.linspace(-1, 3.5)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')\n",
    "\n",
    "for m, b, d in [(1, 0.65, 0.33), (0.5, 1.6, 0.55), (-0.2, 2.9, 0.2)]:\n",
    "    yfit = m * xfit + b\n",
    "    plt.plot(xfit, yfit, '-k')\n",
    "    plt.fill_between(xfit, yfit - d, yfit + d, edgecolor='none',\n",
    "                     color='#AAAAAA', alpha=0.4)\n",
    "\n",
    "plt.xlim(-1, 3.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In support vector machines, the line that maximizes this margin is the one we will choose as the optimal model. Support vector machines are an example of such a maximum margin estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVMs on the data, Running the model with scaled data to improve the accuracy \n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# lets investigate SVMs on the data and play with the parameters and kernels\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# train the model just as before\n",
    "svm_clf = SVC(C=0.5, kernel='rbf', degree=3, gamma='auto') # get object\n",
    "svm_clf.fit(X_train_scaled, y_train)  # train object\n",
    "\n",
    "y_hat = svm_clf.predict(X_test_scaled) # get test set precitions\n",
    "\n",
    "acc = mt.accuracy_score(y_test,y_hat)\n",
    "conf = mt.confusion_matrix(y_test,y_hat)\n",
    "print('accuracy:', acc )\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the support vectors\n",
    "print(svm_clf.support_vectors_.shape)\n",
    "print(svm_clf.support_.shape)\n",
    "print(svm_clf.n_support_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tested_on = Accident_forLr.iloc[train_indices]\n",
    "df_support = df_tested_on.iloc[svm_clf.support_,:]\n",
    "#print(df_support)\n",
    "df_support['within 9 minutes NFPA standard'] = y[svm_clf.support_]  # add back in the  Column to the pandas dataframe\n",
    "Accident_forLr['within 9 minutes NFPA standard'] = y # also add it back in for the original data\n",
    "df_support.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Weight Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the weights below, you can easily tell the direction of the relationship each dependent variable had. A negative value suggests that, if variable is true or increases, the likely hood of an on time arrival would increase as well.  We will need to scale these attributes to see the magnitude each one has on arrival time. \n",
    "\n",
    "Talk about parameters we can change to make model more acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code addapted from the Dataming Notbooks. Logistic Regression Notbook 4.\n",
    "#Generates weights from the LR model.\n",
    "\n",
    "\n",
    "# iterate over the coefficients \n",
    "weights = OnTime_lr_clf.coef_.T # take transpose to make a column vector\n",
    "variable_names = Accident_forLr.columns\n",
    "for coef, name in zip(weights,variable_names):\n",
    "    print(name, 'has weight of', coef[0])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discuses in meeting \n",
    "Weights changed to negative \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# we want to normalize the features based upon the mean and standard deviation of each column. \n",
    "# However, we do not want to accidentally use the testing data to find out the mean and std (this would be snooping)\n",
    "# to Make things easier, let's start by just using whatever was last stored in the variables:\n",
    "##    X_train , y_train , X_test, y_test (they were set in a for loop above)\n",
    "\n",
    "# scale attributes by the training set\n",
    "scl_obj = StandardScaler()\n",
    "scl_obj.fit(X_train) # find scalings for each column that make this zero mean and unit std\n",
    "# the line of code above only looks at training data to get mean and std and we can use it \n",
    "# to transform new feature data\n",
    "\n",
    "X_train_scaled = scl_obj.transform(X_train) # apply to training\n",
    "X_test_scaled = scl_obj.transform(X_test) # apply those means and std to the test set (without snooping at the test set values)\n",
    "\n",
    "# train the model just as before\n",
    "OnTime_lr_clf = LogisticRegression(penalty='l2', C=0.05) # get object, the 'C' value is less (can you guess why??)\n",
    "OnTime_lr_clf.fit(X_train_scaled,y_train)  # train object\n",
    "\n",
    "y_hat = OnTime_lr_clf.predict(X_test_scaled) # get test set precitions\n",
    "\n",
    "acc = mt.accuracy_score(y_test,y_hat)\n",
    "conf = mt.confusion_matrix(y_test,y_hat)\n",
    "print('accuracy:', acc )\n",
    "print(conf )\n",
    "\n",
    "# sort these attributes and spit them out\n",
    "zip_vars = zip(OnTime_lr_clf.coef_.T,Accident_forLr.columns) # combine attributes\n",
    "zip_vars = sorted(zip_vars)\n",
    "for coef, name in zip_vars:\n",
    "    print(name, 'has weight of', coef[0]) # now print them out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights based on the Classification Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#traffic might suck more than living in the country??\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
